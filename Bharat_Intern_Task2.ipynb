{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "29GrwvoneeXK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "56AScCmdcrtY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Display basic info about the dataset\n",
        "print(train_df.info())\n",
        "print(test_df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zurl9Uevetiq",
        "outputId": "79d4a2cb-d962-4fbd-b1bb-3dbea98edb69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine datasets for easier preprocessing\n",
        "combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
        "\n",
        "# Handle missing values\n",
        "combined_df['Age'].fillna(combined_df['Age'].median(), inplace=True)\n",
        "combined_df['Fare'].fillna(combined_df['Fare'].median(), inplace=True)\n",
        "combined_df['Embarked'].fillna(combined_df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Feature engineering: Extract titles from names\n",
        "combined_df['Title'] = combined_df['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
        "\n",
        "# Mapping titles to categories\n",
        "title_mapping = {\n",
        "    'Mr': 'Mr',\n",
        "    'Miss': 'Miss',\n",
        "    'Mrs': 'Mrs',\n",
        "    'Master': 'Master',\n",
        "    'Dr': 'Other',\n",
        "    'Rev': 'Other',\n",
        "    'Col': 'Other',\n",
        "    'Major': 'Other',\n",
        "    'Mlle': 'Miss',\n",
        "    'Countess': 'Other',\n",
        "    'Ms': 'Miss',\n",
        "    'Lady': 'Other',\n",
        "    'Jonkheer': 'Other',\n",
        "    'Don': 'Other',\n",
        "    'Mme': 'Mrs',\n",
        "    'Capt': 'Other',\n",
        "    'Sir': 'Other'\n",
        "}\n",
        "combined_df['Title'] = combined_df['Title'].map(title_mapping)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoders = {}\n",
        "for feature in ['Sex', 'Embarked', 'Title']:\n",
        "    label_encoders[feature] = LabelEncoder()\n",
        "    combined_df[feature] = label_encoders[feature].fit_transform(combined_df[feature])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "combined_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# Split back into train and test datasets\n",
        "train_processed = combined_df.iloc[:len(train_df)]\n",
        "test_processed = combined_df.iloc[len(train_df):].drop('Survived', axis=1)\n"
      ],
      "metadata": {
        "id": "XApuGp8kfIs4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_processed.drop('Survived', axis=1)\n",
        "y = train_processed['Survived']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zQeH_9jOk77E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define parameters for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV to find best parameters\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Initialize model with best parameters\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL0beubdk_Q5",
        "outputId": "df06d1eb-60b3-46de-85ef-0ace23fa6c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "test_predictions = model.predict(test_processed)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_df['PassengerId'],\n",
        "    'Survived': test_predictions\n",
        "})\n",
        "\n",
        "# Save submission to CSV\n",
        "submission.to_csv('titanic_submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Z7NGg742lWMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}